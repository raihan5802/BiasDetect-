{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import joblib\n",
        "from textblob import TextBlob  # For sentiment analysis\n",
        "from thop import profile"
      ],
      "metadata": {
        "id": "MxZfuaO8prMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Understanding the Dataset**"
      ],
      "metadata": {
        "id": "etTOd7R4zLb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Inspect the Dataset"
      ],
      "metadata": {
        "id": "XR7q6euYq4N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/HerWill/train.csv')\n",
        "\n",
        "# Display the first few rows to understand the data structure\n",
        "print(\"First 5 rows of the training dataset:\")\n",
        "display(train_df.head())\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset Information:\")\n",
        "train_df.info()\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "print(\"\\nMissing Values in Each Column:\")\n",
        "print(train_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "ZE2jxJEtrDT8",
        "outputId": "d17e1409-ff93-4938-b471-30a2f6b5d828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the training dataset:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   id                                            passage  y\n",
              "0   0  Women are always the ones struggling in math c...  1\n",
              "1   1  Men in education often just boss around and ne...  0\n",
              "2   2  Non-binary students are just confused about th...  2\n",
              "3   3  Science classrooms are designed to be neutral ...  3\n",
              "4   4  Male teachers often believe they are superior ...  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b63b4160-3c3c-4824-b748-64d95fbeecf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>passage</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Women are always the ones struggling in math c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Men in education often just boss around and ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Non-binary students are just confused about th...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Science classrooms are designed to be neutral ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Male teachers often believe they are superior ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b63b4160-3c3c-4824-b748-64d95fbeecf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b63b4160-3c3c-4824-b748-64d95fbeecf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b63b4160-3c3c-4824-b748-64d95fbeecf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-384e0095-eea7-4734-8c75-cf2b8f6dcad5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-384e0095-eea7-4734-8c75-cf2b8f6dcad5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-384e0095-eea7-4734-8c75-cf2b8f6dcad5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(train_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"passage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Men in education often just boss around and never listen to others' ideas. They think they know everything, but their arrogance gets in the way of true learning.\",\n          \"Male teachers often believe they are superior to female teachers. They try to dominate staff meetings and dismiss the contributions of their female colleagues.\",\n          \"Non-binary students are just confused about their identity. How can they focus on their studies when they can't even decide who they are?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7000 entries, 0 to 6999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   id       7000 non-null   int64 \n",
            " 1   passage  7000 non-null   object\n",
            " 2   y        7000 non-null   int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 164.2+ KB\n",
            "\n",
            "Missing Values in Each Column:\n",
            "id         0\n",
            "passage    0\n",
            "y          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "BB75073fsEcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the text data to ensure consistency and remove unwanted characters\n",
        "def clean_text(text):\n",
        "\n",
        "    # Clean the input text by converting to lowercase and removing non-alphanumeric characters.\n",
        "\n",
        "    text = text.lower()  # Convert text to lowercase to avoid case issues\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove non-alphabetic characters\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the 'passage' column in the training set\n",
        "train_df['cleaned_passage'] = train_df['passage'].apply(clean_text)\n",
        "\n",
        "# Display the cleaned passages\n",
        "print(\"Sample cleaned passages:\")\n",
        "display(train_df[['passage', 'cleaned_passage']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "UNIrvZTOrNp3",
        "outputId": "f0962455-4192-4462-aa69-3c504a88b0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample cleaned passages:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             passage  \\\n",
              "0  Women are always the ones struggling in math c...   \n",
              "1  Men in education often just boss around and ne...   \n",
              "2  Non-binary students are just confused about th...   \n",
              "3  Science classrooms are designed to be neutral ...   \n",
              "4  Male teachers often believe they are superior ...   \n",
              "\n",
              "                                     cleaned_passage  \n",
              "0  women are always the ones struggling in math c...  \n",
              "1  men in education often just boss around and ne...  \n",
              "2  nonbinary students are just confused about the...  \n",
              "3  science classrooms are designed to be neutral ...  \n",
              "4  male teachers often believe they are superior ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33118248-df60-4f71-8436-4b859a6b15bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passage</th>\n",
              "      <th>cleaned_passage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Women are always the ones struggling in math c...</td>\n",
              "      <td>women are always the ones struggling in math c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Men in education often just boss around and ne...</td>\n",
              "      <td>men in education often just boss around and ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Non-binary students are just confused about th...</td>\n",
              "      <td>nonbinary students are just confused about the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Science classrooms are designed to be neutral ...</td>\n",
              "      <td>science classrooms are designed to be neutral ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male teachers often believe they are superior ...</td>\n",
              "      <td>male teachers often believe they are superior ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33118248-df60-4f71-8436-4b859a6b15bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33118248-df60-4f71-8436-4b859a6b15bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33118248-df60-4f71-8436-4b859a6b15bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7317e307-f55d-4a49-9092-35eed22cb345\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7317e307-f55d-4a49-9092-35eed22cb345')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7317e307-f55d-4a49-9092-35eed22cb345 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(train_df[['passage', 'cleaned_passage']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"passage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Men in education often just boss around and never listen to others' ideas. They think they know everything, but their arrogance gets in the way of true learning.\",\n          \"Male teachers often believe they are superior to female teachers. They try to dominate staff meetings and dismiss the contributions of their female colleagues.\",\n          \"Non-binary students are just confused about their identity. How can they focus on their studies when they can't even decide who they are?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_passage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"men in education often just boss around and never listen to others ideas they think they know everything but their arrogance gets in the way of true learning\",\n          \"male teachers often believe they are superior to female teachers they try to dominate staff meetings and dismiss the contributions of their female colleagues\",\n          \"nonbinary students are just confused about their identity how can they focus on their studies when they cant even decide who they are\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Keyword Categories for Each Class"
      ],
      "metadata": {
        "id": "1mxfzgUqshB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check the presence of any keywords in a passage\n",
        "def contains_keywords(text, keywords):\n",
        "    # Check if any of the provided keywords are present in the text\n",
        "    return any(keyword in text for keyword in keywords)\n",
        "\n",
        "# Define keywords for each class\n",
        "class_0_keywords = ['man', 'men', 'male', 'boy', 'boys']\n",
        "class_1_keywords = ['woman', 'women', 'female', 'girl', 'girls']\n",
        "class_2_keywords = ['non-binary', 'non binary']\n",
        "class_3_keywords = class_0_keywords + class_1_keywords + class_2_keywords  # Combined keywords for class 3\n"
      ],
      "metadata": {
        "id": "kO3kOWbjsUm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Dataset Analysis"
      ],
      "metadata": {
        "id": "Fsglo32ts5oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Count the number of rows for each class\n",
        "class_counts = train_df['y'].value_counts()\n",
        "print(\"Class Counts:\\n\", class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YX16Q-Os1OF",
        "outputId": "efdbc8b8-ae85-424e-bac6-b4a990e51b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Counts:\n",
            " y\n",
            "1    2087\n",
            "2    1891\n",
            "0    1811\n",
            "3    1211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Analyze Class 0: Passages containing and not containing class_0_keywords\n",
        "class_0_passages = train_df[train_df['y'] == 0]\n",
        "class_0_with_keywords = class_0_passages['cleaned_passage'].apply(lambda x: contains_keywords(x, class_0_keywords)).sum()\n",
        "class_0_without_keywords = len(class_0_passages) - class_0_with_keywords\n",
        "print(f\"\\nClass 0 passages with keywords {class_0_keywords}: {class_0_with_keywords}\")\n",
        "print(f\"Class 0 passages without keywords {class_0_keywords}: {class_0_without_keywords}\")\n",
        "\n",
        "# 3. Analyze Class 1: Passages containing and not containing class_1_keywords\n",
        "class_1_passages = train_df[train_df['y'] == 1]\n",
        "class_1_with_keywords = class_1_passages['cleaned_passage'].apply(lambda x: contains_keywords(x, class_1_keywords)).sum()\n",
        "class_1_without_keywords = len(class_1_passages) - class_1_with_keywords\n",
        "print(f\"\\nClass 1 passages with keywords {class_1_keywords}: {class_1_with_keywords}\")\n",
        "print(f\"Class 1 passages without keywords {class_1_keywords}: {class_1_without_keywords}\")\n",
        "\n",
        "# 4. Analyze Class 2: Passages containing and not containing class_2_keywords\n",
        "class_2_passages = train_df[train_df['y'] == 2]\n",
        "class_2_with_keywords = class_2_passages['cleaned_passage'].apply(lambda x: contains_keywords(x, class_2_keywords)).sum()\n",
        "class_2_without_keywords = len(class_2_passages) - class_2_with_keywords\n",
        "print(f\"\\nClass 2 passages with keywords {class_2_keywords}: {class_2_with_keywords}\")\n",
        "print(f\"Class 2 passages without keywords {class_2_keywords}: {class_2_without_keywords}\")\n",
        "\n",
        "# 5. Analyze Class 3: Passages containing any class_3_keywords\n",
        "class_3_passages = train_df[train_df['y'] == 3]\n",
        "class_3_with_keywords = class_3_passages['cleaned_passage'].apply(lambda x: contains_keywords(x, class_3_keywords)).sum()\n",
        "print(f\"\\nClass 3 passages with any keywords {class_3_keywords}: {class_3_with_keywords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuQ0yPies-E1",
        "outputId": "72619dfd-85bc-479a-b29f-b5240b76eba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class 0 passages with keywords ['man', 'men', 'male', 'boy', 'boys']: 1806\n",
            "Class 0 passages without keywords ['man', 'men', 'male', 'boy', 'boys']: 5\n",
            "\n",
            "Class 1 passages with keywords ['woman', 'women', 'female', 'girl', 'girls']: 2068\n",
            "Class 1 passages without keywords ['woman', 'women', 'female', 'girl', 'girls']: 19\n",
            "\n",
            "Class 2 passages with keywords ['non-binary', 'non binary']: 0\n",
            "Class 2 passages without keywords ['non-binary', 'non binary']: 1891\n",
            "\n",
            "Class 3 passages with any keywords ['man', 'men', 'male', 'boy', 'boys', 'woman', 'women', 'female', 'girl', 'girls', 'non-binary', 'non binary']: 526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Analysis"
      ],
      "metadata": {
        "id": "I6Ehz6CxtPr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall presence of keywords across all classes\n",
        "overall_keyword_counts = {\n",
        "    'class_0_keywords': train_df['cleaned_passage'].apply(lambda x: contains_keywords(x, class_0_keywords)).sum(),\n",
        "    'class_1_keywords': train_df['cleaned_passage'].apply(lambda x: contains_keywords(x, class_1_keywords)).sum(),\n",
        "    'class_2_keywords': train_df['cleaned_passage'].apply(lambda x: contains_keywords(x, class_2_keywords)).sum(),\n",
        "    'class_3_keywords': train_df['cleaned_passage'].apply(lambda x: contains_keywords(x, class_3_keywords)).sum(),\n",
        "}\n",
        "\n",
        "print(\"\\nOverall Keyword Counts in the Dataset:\")\n",
        "for keyword_class, count in overall_keyword_counts.items():\n",
        "    print(f\"{keyword_class}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reH0mlC3tJb9",
        "outputId": "a4c8c48e-78bf-4e6a-8a2f-24c2cbac1795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Keyword Counts in the Dataset:\n",
            "class_0_keywords: 4934\n",
            "class_1_keywords: 2443\n",
            "class_2_keywords: 0\n",
            "class_3_keywords: 4937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the Most Frequent Words in Each Class\n",
        "def most_frequent_words(passages, n=10):\n",
        "    \"\"\"\n",
        "    Find the most frequent words in a list of passages.\n",
        "\n",
        "    Parameters:\n",
        "        passages (Series): Pandas Series containing text data.\n",
        "        n (int): Number of top frequent words to return.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tuples with words and their corresponding counts.\n",
        "    \"\"\"\n",
        "    words = ' '.join(passages).split()\n",
        "    return Counter(words).most_common(n)\n",
        "\n",
        "# Analyze and display the most frequent words for each class\n",
        "for class_label in [0, 1, 2, 3]:\n",
        "    class_passages = train_df[train_df['y'] == class_label]['cleaned_passage']\n",
        "    frequent_words = most_frequent_words(class_passages)\n",
        "    print(f\"\\nMost frequent words in Class {class_label} (Top 10): {frequent_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlZm825ZtXgd",
        "outputId": "60e137e6-0500-4cae-e18b-feb3c4a33f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most frequent words in Class 0 (Top 10): [('to', 1259), ('men', 1064), ('the', 1053), ('and', 1014), ('in', 991), ('their', 849), ('are', 779), ('often', 753), ('they', 670), ('of', 626)]\n",
            "\n",
            "Most frequent words in Class 1 (Top 10): [('to', 1459), ('women', 1408), ('in', 1162), ('the', 1140), ('and', 1109), ('their', 1079), ('are', 989), ('often', 800), ('they', 634), ('female', 571)]\n",
            "\n",
            "Most frequent words in Class 2 (Top 10): [('nonbinary', 1821), ('their', 1378), ('to', 1276), ('and', 851), ('the', 812), ('often', 765), ('in', 757), ('individuals', 680), ('are', 627), ('for', 494)]\n",
            "\n",
            "Most frequent words in Class 3 (Top 10): [('and', 1007), ('of', 770), ('to', 726), ('the', 719), ('gender', 649), ('a', 501), ('their', 451), ('in', 441), ('that', 405), ('all', 388)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the Most Common Bigrams in Each Class\n",
        "def most_common_bigrams(passages, n=10):\n",
        "    \"\"\"\n",
        "    Find the most common bigrams (pairs of words) in a list of passages.\n",
        "\n",
        "    Parameters:\n",
        "        passages (Series): Pandas Series containing text data.\n",
        "        n (int): Number of top bigrams to return.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tuples with bigrams and their corresponding counts.\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer(ngram_range=(2, 2), stop_words='english')\n",
        "    X_bigrams = vectorizer.fit_transform(passages)\n",
        "    bigram_counts = X_bigrams.sum(axis=0).A1\n",
        "    bigrams = vectorizer.get_feature_names_out()\n",
        "    bigram_freq = list(zip(bigrams, bigram_counts))\n",
        "    bigram_freq.sort(key=lambda x: x[1], reverse=True)\n",
        "    return bigram_freq[:n]\n",
        "\n",
        "# Analyze and display the most common bigrams for each class\n",
        "for class_label in [0, 1, 2, 3]:\n",
        "    class_passages = train_df[train_df['y'] == class_label]['cleaned_passage']\n",
        "    common_bigrams = most_common_bigrams(class_passages)\n",
        "    print(f\"\\nMost common bigrams in Class {class_label} (Top 10): {common_bigrams}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIEKb-JQtw4f",
        "outputId": "3b97f766-0655-4b51-fda3-4f55575e58b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most common bigrams in Class 0 (Top 10): [('men think', 74), ('male nurses', 66), ('patient care', 57), ('male pharmacists', 41), ('think know', 40), ('mental health', 39), ('think theyre', 37), ('female colleagues', 36), ('lack empathy', 34), ('male dentists', 34)]\n",
            "\n",
            "Most common bigrams in Class 1 (Top 10): [('male counterparts', 104), ('women lack', 73), ('leadership roles', 69), ('women handle', 64), ('women tend', 60), ('women generally', 50), ('compared male', 49), ('women just', 48), ('male colleagues', 46), ('female patients', 43)]\n",
            "\n",
            "Most common bigrams in Class 2 (Top 10): [('nonbinary individuals', 634), ('nonbinary people', 382), ('gender identity', 202), ('people just', 78), ('identity issues', 65), ('just trying', 63), ('individuals face', 50), ('individuals just', 46), ('nonbinary healthcare', 45), ('nonbinary photographers', 42)]\n",
            "\n",
            "Most common bigrams in Class 3 (Top 10): [('regardless gender', 196), ('gender identity', 173), ('nonbinary individuals', 70), ('irrespective gender', 41), ('gender identities', 37), ('equal opportunities', 29), ('male nurses', 26), ('occupational therapy', 26), ('behavioral neuroscience', 25), ('gender equality', 23)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Analyze Sentence Length Distribution Across Classes\n",
        "\n",
        "# Calculate the number of words in each passage\n",
        "train_df['sentence_length'] = train_df['cleaned_passage'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# For each class, compute average, minimum, and maximum sentence lengths\n",
        "for class_label in [0, 1, 2, 3]:\n",
        "    class_sentence_lengths = train_df[train_df['y'] == class_label]['sentence_length']\n",
        "    avg_length = class_sentence_lengths.mean()\n",
        "    min_length = class_sentence_lengths.min()\n",
        "    max_length = class_sentence_lengths.max()\n",
        "    print(f\"\\nClass {class_label} Sentence Lengths:\")\n",
        "    print(f\"Average: {avg_length:.2f}, Min: {min_length}, Max: {max_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdpXMaEGt53c",
        "outputId": "e0bb051a-fce3-4b33-ebc0-bee831cc5d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class 0 Sentence Lengths:\n",
            "Average: 20.72, Min: 5, Max: 56\n",
            "\n",
            "Class 1 Sentence Lengths:\n",
            "Average: 21.11, Min: 5, Max: 164\n",
            "\n",
            "Class 2 Sentence Lengths:\n",
            "Average: 19.88, Min: 6, Max: 60\n",
            "\n",
            "Class 3 Sentence Lengths:\n",
            "Average: 21.41, Min: 9, Max: 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze Positional Keyword Bias (e.g., first 5 words of passage)\n",
        "def starts_with_keywords(text, keywords, num_words=5):\n",
        "    \"\"\"\n",
        "    Check if any of the keywords appear within the first 'num_words' of the text.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text to search within.\n",
        "        keywords (list): A list of keywords to search for.\n",
        "        num_words (int): Number of words from the start to consider.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if any keyword is found in the specified position, False otherwise.\n",
        "    \"\"\"\n",
        "    words = text.split()[:num_words]  # Extract the first 'num_words' words\n",
        "    return contains_keywords(' '.join(words), keywords)\n",
        "\n",
        "# For each class, count how many passages have keywords in the first 5 words\n",
        "for class_label, keywords in [(0, class_0_keywords), (1, class_1_keywords), (2, class_2_keywords)]:\n",
        "    class_passages = train_df[train_df['y'] == class_label]\n",
        "    positional_bias = class_passages['cleaned_passage'].apply(lambda x: starts_with_keywords(x, keywords)).sum()\n",
        "    print(f\"\\nClass {class_label} passages where first 5 words contain keywords {keywords}: {positional_bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xhZ8cp8uDxF",
        "outputId": "423eedf3-93b5-4245-cd04-ccb6248fd22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class 0 passages where first 5 words contain keywords ['man', 'men', 'male', 'boy', 'boys']: 1743\n",
            "\n",
            "Class 1 passages where first 5 words contain keywords ['woman', 'women', 'female', 'girl', 'girls']: 1789\n",
            "\n",
            "Class 2 passages where first 5 words contain keywords ['non-binary', 'non binary']: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze Unique Words in Each Class\n",
        "def get_unique_words(passages):\n",
        "    \"\"\"\n",
        "    Extract unique words from a list of passages.\n",
        "\n",
        "    Parameters:\n",
        "        passages (Series): Pandas Series containing text data.\n",
        "\n",
        "    Returns:\n",
        "        set: A set of unique words.\n",
        "    \"\"\"\n",
        "    words = ' '.join(passages).split()\n",
        "    return set(words)\n",
        "\n",
        "# Extract unique words for each class\n",
        "unique_words_per_class = {}\n",
        "for class_label in [0, 1, 2, 3]:\n",
        "    class_passages = train_df[train_df['y'] == class_label]['cleaned_passage']\n",
        "    unique_words_per_class[class_label] = get_unique_words(class_passages)\n",
        "\n",
        "# Display the number of unique words in each class\n",
        "for class_label in [0, 1, 2, 3]:\n",
        "    print(f\"\\nNumber of unique words in Class {class_label}: {len(unique_words_per_class[class_label])}\")\n",
        "\n",
        "# Identify and display words that are unique to each class\n",
        "for class_label in [0, 1, 2, 3]:\n",
        "    other_classes = [label for label in [0, 1, 2, 3] if label != class_label]\n",
        "    unique_words = unique_words_per_class[class_label] - set().union(*[unique_words_per_class[label] for label in other_classes])\n",
        "    print(f\"\\nWords unique to Class {class_label}: {list(unique_words)[:10]}\")  # Display first 10 unique words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrwNt_n-uM0O",
        "outputId": "981fe0d6-8281-4f83-ad11-473d6d7641ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of unique words in Class 0: 3387\n",
            "\n",
            "Number of unique words in Class 1: 3601\n",
            "\n",
            "Number of unique words in Class 2: 2772\n",
            "\n",
            "Number of unique words in Class 3: 2698\n",
            "\n",
            "Words unique to Class 0: ['miracle', 'maledominant', 'nonmale', 'progressively', 'anymore', 'procedural', 'inconsiderate', 'groomed', 'knowitall', 'midwifery']\n",
            "\n",
            "Words unique to Class 1: ['predictions', 'submitted', 'rappers', 'got', 'detrimentally', 'troubleshooting', 'olympics', 'temptresses', 'logically', 'hockey']\n",
            "\n",
            "Words unique to Class 2: ['norm', 'eccentric', 'egypt', 'bandwagon', 'survive', 'showings', 'rejecting', 'nonstandard', 'feasible', 'tick']\n",
            "\n",
            "Words unique to Class 3: ['movie', 'volunteering', 'furniture', 'wellconnected', 'enable', 'bravery', 'zero', 'activity', 'determining', 'honorably']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Analyze the Impact of Stopword Removal\n",
        "\n",
        "# Define a set of common stopwords\n",
        "stopwords = set(['is', 'are', 'the', 'a', 'an', 'and', 'but', 'or', 'if', 'then', 'there'])\n",
        "\n",
        "# Remove stopwords from the cleaned passages\n",
        "train_df['cleaned_passage_no_stopwords'] = train_df['cleaned_passage'].apply(\n",
        "    lambda x: ' '.join([word for word in x.split() if word not in stopwords])\n",
        ")\n",
        "\n",
        "# Compare passages before and after stopword removal for Class 0\n",
        "print(f\"\\nOriginal passage (Class 0):\\n{train_df[train_df['y'] == 0]['cleaned_passage'].iloc[0]}\")\n",
        "print(f\"\\nPassage without stopwords (Class 0):\\n{train_df[train_df['y'] == 0]['cleaned_passage_no_stopwords'].iloc[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRALlrGruSgk",
        "outputId": "b5d38476-059c-4e89-bb49-0e6a05ee4d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original passage (Class 0):\n",
            "men in education often just boss around and never listen to others ideas they think they know everything but their arrogance gets in the way of true learning\n",
            "\n",
            "Passage without stopwords (Class 0):\n",
            "men in education often just boss around never listen to others ideas they think they know everything their arrogance gets in way of true learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find common co-occurring words in Class 3 with biased keywords\n",
        "\n",
        "def co_occurring_words_with_keywords(text, keywords):\n",
        "    \"\"\"\n",
        "    Extract words from the text that are not in the specified keywords.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text to process.\n",
        "        keywords (list): List of keywords to exclude.\n",
        "\n",
        "    Returns:\n",
        "        list: List of co-occurring words not in keywords.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    return [word for word in words if word not in keywords]\n",
        "\n",
        "# Identify Class 3 passages that contain any class_3_keywords\n",
        "class_3_passages_with_keywords = class_3_passages['cleaned_passage'].apply(\n",
        "    lambda x: contains_keywords(x, class_3_keywords)\n",
        ")\n",
        "\n",
        "# Filter passages that contain class_3_keywords\n",
        "class_3_passages_with_keywords = class_3_passages[class_3_passages['cleaned_passage'].apply(\n",
        "    lambda x: contains_keywords(x, class_3_keywords)\n",
        ")]\n",
        "\n",
        "# Initialize a Counter to hold co-occurring words\n",
        "co_occurring_words = Counter()\n",
        "\n",
        "# Collect co-occurring words from Class 3 passages with keywords\n",
        "for passage in class_3_passages_with_keywords['cleaned_passage']:\n",
        "    co_occurring_words.update(co_occurring_words_with_keywords(passage, class_3_keywords))\n",
        "\n",
        "# Display the top 20 co-occurring words\n",
        "print(\"\\nTop co-occurring words with biased keywords in Class 3:\")\n",
        "print(co_occurring_words.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYYPWV4euc5d",
        "outputId": "a8f6b597-25e8-412d-d08e-725131f19f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top co-occurring words with biased keywords in Class 3:\n",
            "[('and', 429), ('to', 333), ('the', 325), ('of', 315), ('gender', 226), ('that', 224), ('in', 219), ('their', 218), ('a', 215), ('for', 166), ('is', 157), ('are', 156), ('all', 156), ('often', 102), ('this', 100), ('more', 91), ('environment', 82), ('nonbinary', 75), ('should', 73), ('can', 73)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis using TextBlob\n",
        "\n",
        "# Apply sentiment analysis to all Class 3 passages\n",
        "class_3_passages = train_df[train_df['y'] == 3].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
        "class_3_passages['sentiment'] = class_3_passages['cleaned_passage'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Apply sentiment analysis to Class 3 passages with keywords\n",
        "class_3_passages_with_keywords['sentiment'] = class_3_passages_with_keywords['cleaned_passage'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Calculate average sentiment scores\n",
        "avg_sentiment_class_3 = class_3_passages['sentiment'].mean()\n",
        "avg_sentiment_class_3_with_keywords = class_3_passages_with_keywords['sentiment'].mean()\n",
        "\n",
        "print(f\"\\nAverage sentiment for all Class 3 passages: {avg_sentiment_class_3:.2f}\")\n",
        "print(f\"Average sentiment for Class 3 passages with biased keywords: {avg_sentiment_class_3_with_keywords:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnjwF02oughE",
        "outputId": "1d5b721d-19b5-4324-9860-49d91631f425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average sentiment for all Class 3 passages: 0.17\n",
            "Average sentiment for Class 3 passages with biased keywords: 0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to extract top N-grams (bigrams or trigrams)\n",
        "def get_top_ngrams(corpus, n=None, ngram_range=(2, 3)):\n",
        "    \"\"\"\n",
        "    Extract the top N n-grams from the corpus.\n",
        "\n",
        "    Parameters:\n",
        "        corpus (list): List of text documents.\n",
        "        n (int): Number of top n-grams to return.\n",
        "        ngram_range (tuple): The range of n-values for different n-grams to be extracted.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tuples with n-grams and their corresponding counts.\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words='english').fit(corpus)\n",
        "    bag_of_words = vectorizer.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
        "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "metadata": {
        "id": "Kwbssm-9ulh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 20 bigrams and trigrams for Class 3\n",
        "corpus_class_3 = class_3_passages['cleaned_passage'].tolist()\n",
        "top_20_bigrams_class_3 = get_top_ngrams(corpus_class_3, n=20, ngram_range=(2, 2))\n",
        "top_20_trigrams_class_3 = get_top_ngrams(corpus_class_3, n=20, ngram_range=(3, 3))\n",
        "\n",
        "print(\"\\nTop 20 Bigrams in Class 3:\")\n",
        "print(top_20_bigrams_class_3)\n",
        "\n",
        "print(\"\\nTop 20 Trigrams in Class 3:\")\n",
        "print(top_20_trigrams_class_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aIlLb1UurZV",
        "outputId": "be812c8a-a362-46d6-d1c8-b2ec72dea233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 Bigrams in Class 3:\n",
            "[('regardless gender', 196), ('gender identity', 173), ('nonbinary individuals', 70), ('irrespective gender', 41), ('gender identities', 37), ('equal opportunities', 29), ('occupational therapy', 26), ('male nurses', 26), ('behavioral neuroscience', 25), ('identity expression', 23), ('gender equality', 23), ('based gender', 22), ('diverse perspectives', 22), ('people genders', 22), ('inclusive environment', 21), ('patient care', 21), ('mental health', 21), ('rehabilitation counseling', 19), ('transcends gender', 18), ('gender diversity', 17)]\n",
            "\n",
            "Top 20 Trigrams in Class 3:\n",
            "[('regardless gender identity', 72), ('gender identity expression', 23), ('irrespective gender identity', 17), ('based gender identity', 14), ('nonbinary individuals face', 13), ('individuals regardless gender', 12), ('unconventional gender identity', 12), ('nonbinary individuals nursing', 11), ('nonprofits face misconception', 11), ('male female nonbinary', 9), ('create inclusive environment', 9), ('face significant biases', 9), ('legitimate gender experience', 9), ('gender experience dismissive', 9), ('experience dismissive attitude', 9), ('nurses frequently encounter', 9), ('behavioral neuroscience research', 9), ('face skepticism regarding', 8), ('given equal opportunities', 8), ('treatment regardless gender', 8)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of Phrase Matching for Class 3\n",
        "phrases_class_3 = ['regardless of gender', 'should be equal', 'everyone is treated equally']\n",
        "\n",
        "def phrase_matching(corpus, phrases):\n",
        "    \"\"\"\n",
        "    Count the number of passages that contain specific phrases.\n",
        "\n",
        "    Parameters:\n",
        "        corpus (list): List of text documents.\n",
        "        phrases (list): List of phrases to search for.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with phrase counts.\n",
        "    \"\"\"\n",
        "    phrase_counts = {phrase: 0 for phrase in phrases}\n",
        "    for text in corpus:\n",
        "        for phrase in phrases:\n",
        "            if phrase in text:\n",
        "                phrase_counts[phrase] += 1\n",
        "    return phrase_counts\n",
        "\n",
        "# Perform phrase matching for Class 3\n",
        "phrase_counts_class_3 = phrase_matching(corpus_class_3, phrases_class_3)\n",
        "print(\"\\nPhrase Counts for Class 3:\")\n",
        "print(phrase_counts_class_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovzC7kp5uvmF",
        "outputId": "57692cae-9159-48df-faf3-e54a6e3b9d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phrase Counts for Class 3:\n",
            "{'regardless of gender': 137, 'should be equal': 0, 'everyone is treated equally': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expanded phrase matching for Class 3 (Neutral)\n",
        "phrases_class_3_expanded = [\n",
        "    'regardless of gender', 'equal opportunities', 'inclusive environment', 'gender equality',\n",
        "    'treat everyone equally', 'inclusive society', 'everyone should have the same rights',\n",
        "    'no gender bias', 'regardless of gender identity', 'fair treatment'\n",
        "]\n",
        "\n",
        "# Perform phrase matching for Class 3 with expanded phrases\n",
        "phrase_counts_class_3_expanded = phrase_matching(corpus_class_3, phrases_class_3_expanded)\n",
        "print(\"\\nExpanded Phrase Counts for Class 3 (Neutral):\")\n",
        "print(phrase_counts_class_3_expanded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwMtJROxu0ON",
        "outputId": "85af05f2-a5eb-49c6-ef80-bd0a759cb72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expanded Phrase Counts for Class 3 (Neutral):\n",
            "{'regardless of gender': 137, 'equal opportunities': 29, 'inclusive environment': 24, 'gender equality': 23, 'treat everyone equally': 1, 'inclusive society': 3, 'everyone should have the same rights': 0, 'no gender bias': 0, 'regardless of gender identity': 32, 'fair treatment': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find common co-occurring words in Class 2 with biased keywords\n",
        "\n",
        "def co_occurring_words_with_keywords(text, keywords):\n",
        "    \"\"\"\n",
        "    Extract words from the text that are not in the specified keywords.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text to process.\n",
        "        keywords (list): List of keywords to exclude.\n",
        "\n",
        "    Returns:\n",
        "        list: List of co-occurring words not in keywords.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    return [word for word in words if word not in keywords]\n",
        "\n",
        "# Identify Class 2 passages that contain any class_2_keywords\n",
        "class_2_passages_with_keywords = class_2_passages[class_2_passages['cleaned_passage'].apply(\n",
        "    lambda x: contains_keywords(x, class_2_keywords)\n",
        ")].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
        "\n",
        "# Initialize a Counter to hold co-occurring words\n",
        "co_occurring_words_class_2 = Counter()\n",
        "\n",
        "# Collect co-occurring words from Class 2 passages with keywords\n",
        "for passage in class_2_passages_with_keywords['cleaned_passage']:\n",
        "    co_occurring_words_class_2.update(co_occurring_words_with_keywords(passage, class_2_keywords))\n",
        "\n",
        "# Display the top 20 co-occurring words\n",
        "print(\"\\nTop co-occurring words with biased keywords in Class 2:\")\n",
        "print(co_occurring_words_class_2.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmi3DKagu2vl",
        "outputId": "06c04398-06bd-4105-c8a2-c510e9b654ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top co-occurring words with biased keywords in Class 2:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis for Class 2 using TextBlob\n",
        "\n",
        "# Apply sentiment analysis to all Class 2 passages\n",
        "class_2_passages_copy = class_2_passages.copy()\n",
        "class_2_passages_copy['sentiment'] = class_2_passages_copy['cleaned_passage'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Apply sentiment analysis to Class 2 passages with keywords\n",
        "class_2_passages_with_keywords_copy = class_2_passages_with_keywords.copy()\n",
        "class_2_passages_with_keywords_copy['sentiment'] = class_2_passages_with_keywords_copy['cleaned_passage'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Calculate average sentiment scores\n",
        "avg_sentiment_class_2 = class_2_passages_copy['sentiment'].mean()\n",
        "avg_sentiment_class_2_with_keywords = class_2_passages_with_keywords_copy['sentiment'].mean()\n",
        "\n",
        "print(f\"\\nAverage sentiment for all Class 2 passages: {avg_sentiment_class_2:.2f}\")\n",
        "print(f\"Average sentiment for Class 2 passages with biased keywords: {avg_sentiment_class_2_with_keywords:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtN-DhNBu7l8",
        "outputId": "d92302d8-089d-45c8-edb7-7855b363ff97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average sentiment for all Class 2 passages: 0.03\n",
            "Average sentiment for Class 2 passages with biased keywords: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 20 bigrams and trigrams for Class 2\n",
        "corpus_class_2 = class_2_passages['cleaned_passage'].tolist()\n",
        "top_20_bigrams_class_2 = get_top_ngrams(corpus_class_2, n=20, ngram_range=(2, 2))\n",
        "top_20_trigrams_class_2 = get_top_ngrams(corpus_class_2, n=20, ngram_range=(3, 3))\n",
        "\n",
        "print(\"\\nTop 20 Bigrams in Class 2:\")\n",
        "print(top_20_bigrams_class_2)\n",
        "\n",
        "print(\"\\nTop 20 Trigrams in Class 2:\")\n",
        "print(top_20_trigrams_class_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xzB-5flwcjk",
        "outputId": "0e134565-66a9-407e-a75e-97685f196c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 Bigrams in Class 2:\n",
            "[('nonbinary individuals', 634), ('nonbinary people', 382), ('gender identity', 202), ('people just', 78), ('identity issues', 65), ('just trying', 63), ('individuals face', 50), ('individuals just', 46), ('nonbinary healthcare', 45), ('nonbinary photographers', 42), ('nonbinary employees', 41), ('face challenges', 41), ('nonbinary staff', 41), ('traditional gender', 40), ('making difficult', 37), ('face skepticism', 37), ('special treatment', 37), ('individuals struggle', 37), ('seeking attention', 35), ('nonbinary patients', 35)]\n",
            "\n",
            "Top 20 Trigrams in Class 2:\n",
            "[('nonbinary people just', 63), ('nonbinary individuals face', 44), ('nonbinary individuals struggle', 35), ('nonbinary people face', 34), ('people just trying', 33), ('nonbinary individuals lack', 32), ('nonbinary individuals just', 31), ('nonbinary staff members', 29), ('nonbinary healthcare professionals', 24), ('nonbinary people frequently', 22), ('biases gender identity', 20), ('nonbinary individuals frequently', 18), ('nonbinary individuals bring', 18), ('traditional gender norms', 18), ('healthcare professionals face', 18), ('just seeking attention', 16), ('individuals just trying', 16), ('traditional gender roles', 15), ('gender identity leading', 15), ('nonbinary healthcare workers', 15)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of Phrase Matching for Class 2\n",
        "phrases_class_2 = ['non-binary identity', 'gender identity issues', 'should conform']\n",
        "\n",
        "# Perform phrase matching for Class 2\n",
        "phrase_counts_class_2 = phrase_matching(corpus_class_2, phrases_class_2)\n",
        "print(\"\\nPhrase Counts for Class 2:\")\n",
        "print(phrase_counts_class_2)\n",
        "\n",
        "# Define qualifiers to check in Class 2\n",
        "qualifiers_class_2 = ['just', 'only', 'simply', 'merely']\n",
        "\n",
        "# Count occurrences of qualifiers in Class 2\n",
        "def count_qualifiers(corpus, qualifiers):\n",
        "    \"\"\"\n",
        "    Count the number of passages containing specific qualifiers.\n",
        "\n",
        "    Parameters:\n",
        "        corpus (list): List of text documents.\n",
        "        qualifiers (list): List of qualifiers to search for.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with qualifier counts.\n",
        "    \"\"\"\n",
        "    qualifier_counts = {qualifier: 0 for qualifier in qualifiers}\n",
        "    for text in corpus:\n",
        "        for qualifier in qualifiers:\n",
        "            if qualifier in text:\n",
        "                qualifier_counts[qualifier] += 1\n",
        "    return qualifier_counts\n",
        "\n",
        "qualifier_counts_class_2 = count_qualifiers(corpus_class_2, qualifiers_class_2)\n",
        "print(\"\\nQualifying Phrase Counts for Class 2:\")\n",
        "print(qualifier_counts_class_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRZtD9DgvDOU",
        "outputId": "d0097011-e5c2-4c6c-a395-0e45ed3dcadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phrase Counts for Class 2:\n",
            "{'non-binary identity': 0, 'gender identity issues': 4, 'should conform': 0}\n",
            "\n",
            "Qualifying Phrase Counts for Class 2:\n",
            "{'just': 290, 'only': 15, 'simply': 17, 'merely': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Common conjunctions that could signal complex sentence structures and hidden biases\n",
        "conjunctions = ['but', 'although', 'however', 'even though', 'despite', 'still']\n",
        "\n",
        "# Function to count conjunctions in the corpus\n",
        "def count_conjunctions(corpus, conjunctions):\n",
        "    \"\"\"\n",
        "    Count the number of passages containing specific conjunctions.\n",
        "\n",
        "    Parameters:\n",
        "        corpus (list): List of text documents.\n",
        "        conjunctions (list): List of conjunctions to search for.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with conjunction counts.\n",
        "    \"\"\"\n",
        "    conjunction_counts = {conjunction: 0 for conjunction in conjunctions}\n",
        "    for text in corpus:\n",
        "        for conjunction in conjunctions:\n",
        "            if conjunction in text:\n",
        "                conjunction_counts[conjunction] += 1\n",
        "    return conjunction_counts\n",
        "\n",
        "# Count conjunctions in Class 2 and Class 3\n",
        "conjunction_counts_class_2 = count_conjunctions(corpus_class_2, conjunctions)\n",
        "conjunction_counts_class_3 = count_conjunctions(corpus_class_3, conjunctions)\n",
        "\n",
        "print(\"\\nConjunction Counts for Class 2 (Complex Sentences):\")\n",
        "print(conjunction_counts_class_2)\n",
        "\n",
        "print(\"\\nConjunction Counts for Class 3 (Complex Sentences):\")\n",
        "print(conjunction_counts_class_3)\n",
        "\n",
        "# Pronoun usage analysis\n",
        "pronouns = ['he', 'she', 'they', 'them']\n",
        "\n",
        "# Function to count pronouns in the corpus\n",
        "def count_pronouns(corpus, pronouns):\n",
        "    \"\"\"\n",
        "    Count the number of passages containing specific pronouns.\n",
        "\n",
        "    Parameters:\n",
        "        corpus (list): List of text documents.\n",
        "        pronouns (list): List of pronouns to search for.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with pronoun counts.\n",
        "    \"\"\"\n",
        "    pronoun_counts = {pronoun: 0 for pronoun in pronouns}\n",
        "    for text in corpus:\n",
        "        for pronoun in pronouns:\n",
        "            if pronoun in text:\n",
        "                pronoun_counts[pronoun] += 1\n",
        "    return pronoun_counts\n",
        "\n",
        "# Count pronouns in Class 2 and Class 3\n",
        "pronoun_counts_class_2 = count_pronouns(corpus_class_2, pronouns)\n",
        "pronoun_counts_class_3 = count_pronouns(corpus_class_3, pronouns)\n",
        "\n",
        "print(\"\\nPronoun Counts for Class 2 (Non-Binary Bias):\")\n",
        "print(pronoun_counts_class_2)\n",
        "\n",
        "print(\"\\nPronoun Counts for Class 3 (Neutral):\")\n",
        "print(pronoun_counts_class_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Voftf9J3vJOG",
        "outputId": "f0d69088-5b30-4ddb-a52d-6178d0c4deac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conjunction Counts for Class 2 (Complex Sentences):\n",
            "{'but': 130, 'although': 2, 'however': 2, 'even though': 1, 'despite': 7, 'still': 3}\n",
            "\n",
            "Conjunction Counts for Class 3 (Complex Sentences):\n",
            "{'but': 112, 'although': 0, 'however': 0, 'even though': 0, 'despite': 13, 'still': 5}\n",
            "\n",
            "Pronoun Counts for Class 2 (Non-Binary Bias):\n",
            "{'he': 1722, 'she': 20, 'they': 397, 'them': 244}\n",
            "\n",
            "Pronoun Counts for Class 3 (Neutral):\n",
            "{'he': 1015, 'she': 8, 'they': 76, 'them': 76}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pronoun and Gender Term Co-occurrence\n",
        "\n",
        "def count_co_occurrences(corpus, phrases, keywords):\n",
        "    \"\"\"\n",
        "    Count the number of passages where specific phrases co-occur with any of the keywords.\n",
        "\n",
        "    Parameters:\n",
        "        corpus (list): List of text documents.\n",
        "        phrases (list): List of phrases to search for.\n",
        "        keywords (list): List of keywords to check for co-occurrence.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with co-occurrence counts.\n",
        "    \"\"\"\n",
        "    co_occurrence_counts = {phrase: 0 for phrase in phrases}\n",
        "    for text in corpus:\n",
        "        for phrase in phrases:\n",
        "            if phrase in text:\n",
        "                for keyword in keywords:\n",
        "                    if keyword in text:\n",
        "                        co_occurrence_counts[phrase] += 1\n",
        "                        break  # Only count once if any keyword is present\n",
        "    return co_occurrence_counts\n",
        "\n",
        "# Define gender terms for co-occurrence analysis\n",
        "gender_terms = ['man', 'woman', 'non-binary', 'male', 'female', 'boy', 'girl']\n",
        "\n",
        "# Analyze co-occurrence in Class 2 and Class 3\n",
        "pronoun_and_gender_co_occurrence_class_2 = count_co_occurrences(corpus_class_2, pronouns, gender_terms)\n",
        "pronoun_and_gender_co_occurrence_class_3 = count_co_occurrences(corpus_class_3, pronouns, gender_terms)\n",
        "\n",
        "print(\"\\nPronoun and Gender Term Co-occurrences in Class 2:\")\n",
        "print(pronoun_and_gender_co_occurrence_class_2)\n",
        "\n",
        "print(\"\\nPronoun and Gender Term Co-occurrences in Class 3:\")\n",
        "print(pronoun_and_gender_co_occurrence_class_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by-AgwaJw4g9",
        "outputId": "2be0726a-289f-46fa-f8a7-fc94c33b774a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pronoun and Gender Term Co-occurrences in Class 2:\n",
            "{'he': 150, 'she': 1, 'they': 38, 'them': 18}\n",
            "\n",
            "Pronoun and Gender Term Co-occurrences in Class 3:\n",
            "{'he': 180, 'she': 1, 'they': 25, 'them': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Dataset Inspection: Initially inspecting data structure, types, and missing values is essential to identify potential issues and understand the dataset layout, which informs preprocessing needs.\n",
        "\n",
        "> Text Cleaning: Converting text to lowercase and removing non-alphabetic characters standardizes entries, enabling consistent keyword and phrase detection during analysis.\n",
        "\n",
        "> Keyword Definition by Class: Defining specific keywords related to each class (e.g., male, female, non-binary) helps assess how well keywords alone can distinguish classes, guiding feature engineering decisions.\n",
        "\n",
        "> Class Distribution Check: Analyzing class counts helps identify class imbalance, a critical factor influencing model training and performance across classes.\n",
        "\n",
        "> Keyword Presence Analysis: Checking for the presence or absence of class-specific keywords in passages highlights the relevance of these keywords in differentiating classes.\n",
        "\n",
        "> Overall Keyword Distribution: Reviewing keyword frequencies across all classes reveals patterns and biases in keyword usage, helping adjust for any skew that could impact model training.\n",
        "\n",
        "> Frequent Words per Class: Extracting top words within each class captures unique vocabulary patterns that define each category, providing insights for more effective feature selection.\n",
        "\n",
        "> Common Bigrams: Identifying frequent bigrams adds context by showing commonly associated word pairs, which enhances understanding of class-specific language nuances.\n",
        "\n",
        "> Sentence Length Distribution: Analyzing sentence length across classes reveals structural differences, which can be informative for creating features that capture verbosity or conciseness.\n",
        "\n",
        "> Unique Words per Class: Identifying words unique to each class helps differentiate categories and supports feature engineering by highlighting distinct vocabulary.\n",
        "\n",
        "> Stopword Impact: Removing common stopwords reduces noise, focusing on relevant vocabulary, which clarifies data and improves feature quality.\n",
        "\n",
        "> Co-occurring Words with Biased Keywords: Studying words frequently appearing with biased keywords in certain classes (e.g., Class 3) reveals potential associations and context around biases, guiding targeted feature adjustments.\n"
      ],
      "metadata": {
        "id": "bk3VI07my_zD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Training**"
      ],
      "metadata": {
        "id": "2c2q9Vv0zRrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing and Feature Engineering"
      ],
      "metadata": {
        "id": "XYLmnPcKzYIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training dataset\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/HerWill/train.csv')\n",
        "\n",
        "# Text Preprocessing\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean the text by lowercasing and removing non-alphanumeric characters.\"\"\"\n",
        "    text = text.lower()  # Lowercase all words\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove all non-alphabetic characters\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the 'passage' column in training set\n",
        "train_df['cleaned_passage'] = train_df['passage'].apply(clean_text)\n",
        "\n",
        "# Feature Engineering based on analysis\n",
        "\n",
        "# Define keywords and phrases for feature creation\n",
        "keywords = ['women', 'men', 'nonbinary', 'male', 'female', 'neutral']\n",
        "phrases = ['regardless of gender', 'equal opportunities', 'inclusive environment',\n",
        "           'just', 'but', 'despite', 'he', 'they', 'she']\n",
        "\n",
        "# Add binary features for each keyword in the training data\n",
        "for keyword in keywords:\n",
        "    train_df[keyword] = train_df['cleaned_passage'].apply(lambda x: x.count(keyword))\n",
        "\n",
        "# Add binary features for each phrase in the training data\n",
        "for phrase in phrases:\n",
        "    train_df[phrase] = train_df['cleaned_passage'].apply(lambda x: 1 if phrase in x else 0)\n",
        "\n",
        "# Feature for keyword proximity\n",
        "def keyword_proximity(text):\n",
        "    \"\"\"\n",
        "    Check if any keywords appear within 5 words of each other.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        int: 1 if proximity condition is met, else 0.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    for i, word in enumerate(words):\n",
        "        if word in keywords:\n",
        "            # Check within the next 5 words\n",
        "            for j in range(i+1, min(i+6, len(words))):\n",
        "                if words[j] in keywords and words[j] != word:\n",
        "                    return 1\n",
        "    return 0\n",
        "\n",
        "train_df['keyword_proximity'] = train_df['cleaned_passage'].apply(keyword_proximity)\n",
        "\n",
        "# Add polarity feature using TextBlob\n",
        "def text_polarity(text):\n",
        "    \"\"\"Get the polarity of the text.\"\"\"\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "train_df['polarity'] = train_df['cleaned_passage'].apply(text_polarity)"
      ],
      "metadata": {
        "id": "Rh0mXLcyx8wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorization and Feature Scaling"
      ],
      "metadata": {
        "id": "YbhDObiZzyDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorization\n",
        "# Initialize TF-IDF vectorizer with max_features set to 13 and ngram_range=(1,3)\n",
        "vectorizer = TfidfVectorizer(max_features=13, ngram_range=(1, 3), stop_words='english')\n",
        "\n",
        "# Fit and transform the training data passages\n",
        "X_tfidf = vectorizer.fit_transform(train_df['cleaned_passage'])\n",
        "\n",
        "# Save the trained vectorizer for future use on test data\n",
        "joblib.dump(vectorizer, '/content/drive/MyDrive/HerWill/tfidf_vectorizer.pkl')\n",
        "\n",
        "# Convert the TF-IDF features into a DataFrame\n",
        "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Combine TF-IDF features and binary features from keywords/phrases in the training set\n",
        "additional_features = keywords + phrases + ['keyword_proximity', 'polarity']\n",
        "X_combined = pd.concat([tfidf_df, train_df[additional_features].reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Feature Scaling\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the combined features and transform\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "# Save the scaler for future use on test data\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/HerWill/scaler.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcQr2GntzjDz",
        "outputId": "c9c9d4a2-faf6-46dd-e5dd-7d3cf343296f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/HerWill/scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "gipaOB0r0QfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)  # Reducing features to 3 principal components\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Convert reduced features to a DataFrame\n",
        "X_pca_df = pd.DataFrame(X_pca, columns=[f'pc_{i}' for i in range(1, 3)])\n",
        "\n",
        "# Save PCA model for consistent test data transformation\n",
        "joblib.dump(pca, '/content/drive/MyDrive/HerWill/pca_model.pkl')\n",
        "\n",
        "# Print the number of input features after PCA\n",
        "print(f\"Number of input features after PCA: {X_pca_df.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SnSUD560HI7",
        "outputId": "b3734a1a-f8eb-4174-8fd1-1ca2dacdfce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of input features after PCA: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split and Tensor Conversion"
      ],
      "metadata": {
        "id": "ruhsTT__0fqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "y = train_df['y']  # Target variable\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pca_df, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors for model training\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "Ao35bd7Z0Uvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Neural Network Model"
      ],
      "metadata": {
        "id": "-6DWnFXb0lzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Neural Network Model with very few parameters\n",
        "class MinimalNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MinimalNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 1)  # Single neuron layer\n",
        "        self.fc2 = nn.Linear(1, output_dim)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = torch.sigmoid(out)  # Sigmoid activation for the hidden layer\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = X_pca_df.shape[1]  # Number of input features after PCA (3)\n",
        "output_dim = 4  # Number of output classes (0, 1, 2, 3)\n",
        "\n",
        "# Initialize the model\n",
        "model = MinimalNN(input_dim, output_dim)"
      ],
      "metadata": {
        "id": "lbsqreLT0i0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "rTaImgVB0u0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "n-fu4J_x0rRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop with Validation and Metrics"
      ],
      "metadata": {
        "id": "4gw0dC8H1SoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop with Validation and Metrics\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "num_epochs = 500\n",
        "best_f1_score = 0\n",
        "best_model_weights = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    epoch_loss = 0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    # Training Phase\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Collect predictions for training metrics\n",
        "        _, train_preds = torch.max(outputs, 1)\n",
        "        all_train_preds.extend(train_preds.numpy())\n",
        "        all_train_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate Training Metrics\n",
        "    train_acc = accuracy_score(all_train_labels, all_train_preds)\n",
        "    train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val_tensor)  # Forward pass on validation data\n",
        "        _, y_val_pred = torch.max(val_outputs, 1)  # Get predictions\n",
        "\n",
        "        val_acc = accuracy_score(y_val_tensor, y_val_pred)\n",
        "        val_f1 = f1_score(y_val_tensor, y_val_pred, average='weighted')\n",
        "\n",
        "        # Track the best model based on validation F1 score\n",
        "        if val_f1 > best_f1_score:\n",
        "            best_f1_score = val_f1\n",
        "            best_model_weights = model.state_dict().copy()  # Save the best model weights\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Train Accuracy: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
        "        print(f\"Val Accuracy: {val_acc:.4f}, Val F1: {val_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0NI9znA04IM",
        "outputId": "f326979f-dd57-4982-d081-d7eeef018aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/500], Loss: 1.0390\n",
            "Train Accuracy: 0.5677, Train F1: 0.4341\n",
            "Val Accuracy: 0.5607, Val F1: 0.4251\n",
            "Epoch [20/500], Loss: 0.8909\n",
            "Train Accuracy: 0.5771, Train F1: 0.4522\n",
            "Val Accuracy: 0.5721, Val F1: 0.4464\n",
            "Epoch [30/500], Loss: 0.8270\n",
            "Train Accuracy: 0.6018, Train F1: 0.4993\n",
            "Val Accuracy: 0.6086, Val F1: 0.5162\n",
            "Epoch [40/500], Loss: 0.7898\n",
            "Train Accuracy: 0.6302, Train F1: 0.5500\n",
            "Val Accuracy: 0.6400, Val F1: 0.5680\n",
            "Epoch [50/500], Loss: 0.7622\n",
            "Train Accuracy: 0.6552, Train F1: 0.5897\n",
            "Val Accuracy: 0.6714, Val F1: 0.6154\n",
            "Epoch [60/500], Loss: 0.7401\n",
            "Train Accuracy: 0.6727, Train F1: 0.6159\n",
            "Val Accuracy: 0.6929, Val F1: 0.6498\n",
            "Epoch [70/500], Loss: 0.7218\n",
            "Train Accuracy: 0.7182, Train F1: 0.6869\n",
            "Val Accuracy: 0.7164, Val F1: 0.6847\n",
            "Epoch [80/500], Loss: 0.7062\n",
            "Train Accuracy: 0.7457, Train F1: 0.7228\n",
            "Val Accuracy: 0.7493, Val F1: 0.7292\n",
            "Epoch [90/500], Loss: 0.6929\n",
            "Train Accuracy: 0.7766, Train F1: 0.7604\n",
            "Val Accuracy: 0.7714, Val F1: 0.7562\n",
            "Epoch [100/500], Loss: 0.6816\n",
            "Train Accuracy: 0.7880, Train F1: 0.7738\n",
            "Val Accuracy: 0.7864, Val F1: 0.7744\n",
            "Epoch [110/500], Loss: 0.6719\n",
            "Train Accuracy: 0.7964, Train F1: 0.7835\n",
            "Val Accuracy: 0.8050, Val F1: 0.7955\n",
            "Epoch [120/500], Loss: 0.6636\n",
            "Train Accuracy: 0.8009, Train F1: 0.7884\n",
            "Val Accuracy: 0.8100, Val F1: 0.8011\n",
            "Epoch [130/500], Loss: 0.6564\n",
            "Train Accuracy: 0.8043, Train F1: 0.7925\n",
            "Val Accuracy: 0.8114, Val F1: 0.8027\n",
            "Epoch [140/500], Loss: 0.6502\n",
            "Train Accuracy: 0.8100, Train F1: 0.7991\n",
            "Val Accuracy: 0.8107, Val F1: 0.8022\n",
            "Epoch [150/500], Loss: 0.6449\n",
            "Train Accuracy: 0.8129, Train F1: 0.8023\n",
            "Val Accuracy: 0.8100, Val F1: 0.8018\n",
            "Epoch [160/500], Loss: 0.6402\n",
            "Train Accuracy: 0.8155, Train F1: 0.8053\n",
            "Val Accuracy: 0.8121, Val F1: 0.8042\n",
            "Epoch [170/500], Loss: 0.6363\n",
            "Train Accuracy: 0.8166, Train F1: 0.8065\n",
            "Val Accuracy: 0.8179, Val F1: 0.8107\n",
            "Epoch [180/500], Loss: 0.6329\n",
            "Train Accuracy: 0.8196, Train F1: 0.8099\n",
            "Val Accuracy: 0.8171, Val F1: 0.8099\n",
            "Epoch [190/500], Loss: 0.6298\n",
            "Train Accuracy: 0.8187, Train F1: 0.8090\n",
            "Val Accuracy: 0.8186, Val F1: 0.8118\n",
            "Epoch [200/500], Loss: 0.6273\n",
            "Train Accuracy: 0.8195, Train F1: 0.8102\n",
            "Val Accuracy: 0.8171, Val F1: 0.8103\n",
            "Epoch [210/500], Loss: 0.6249\n",
            "Train Accuracy: 0.8204, Train F1: 0.8111\n",
            "Val Accuracy: 0.8193, Val F1: 0.8125\n",
            "Epoch [220/500], Loss: 0.6228\n",
            "Train Accuracy: 0.8195, Train F1: 0.8103\n",
            "Val Accuracy: 0.8186, Val F1: 0.8123\n",
            "Epoch [230/500], Loss: 0.6210\n",
            "Train Accuracy: 0.8211, Train F1: 0.8120\n",
            "Val Accuracy: 0.8186, Val F1: 0.8123\n",
            "Epoch [240/500], Loss: 0.6193\n",
            "Train Accuracy: 0.8209, Train F1: 0.8121\n",
            "Val Accuracy: 0.8186, Val F1: 0.8123\n",
            "Epoch [250/500], Loss: 0.6178\n",
            "Train Accuracy: 0.8221, Train F1: 0.8134\n",
            "Val Accuracy: 0.8179, Val F1: 0.8115\n",
            "Epoch [260/500], Loss: 0.6165\n",
            "Train Accuracy: 0.8218, Train F1: 0.8130\n",
            "Val Accuracy: 0.8193, Val F1: 0.8126\n",
            "Epoch [270/500], Loss: 0.6153\n",
            "Train Accuracy: 0.8205, Train F1: 0.8118\n",
            "Val Accuracy: 0.8186, Val F1: 0.8123\n",
            "Epoch [280/500], Loss: 0.6141\n",
            "Train Accuracy: 0.8232, Train F1: 0.8147\n",
            "Val Accuracy: 0.8221, Val F1: 0.8162\n",
            "Epoch [290/500], Loss: 0.6131\n",
            "Train Accuracy: 0.8237, Train F1: 0.8155\n",
            "Val Accuracy: 0.8200, Val F1: 0.8140\n",
            "Epoch [300/500], Loss: 0.6122\n",
            "Train Accuracy: 0.8236, Train F1: 0.8152\n",
            "Val Accuracy: 0.8207, Val F1: 0.8148\n",
            "Epoch [310/500], Loss: 0.6114\n",
            "Train Accuracy: 0.8230, Train F1: 0.8148\n",
            "Val Accuracy: 0.8214, Val F1: 0.8157\n",
            "Epoch [320/500], Loss: 0.6105\n",
            "Train Accuracy: 0.8237, Train F1: 0.8157\n",
            "Val Accuracy: 0.8229, Val F1: 0.8171\n",
            "Epoch [330/500], Loss: 0.6098\n",
            "Train Accuracy: 0.8245, Train F1: 0.8163\n",
            "Val Accuracy: 0.8243, Val F1: 0.8187\n",
            "Epoch [340/500], Loss: 0.6091\n",
            "Train Accuracy: 0.8252, Train F1: 0.8171\n",
            "Val Accuracy: 0.8229, Val F1: 0.8172\n",
            "Epoch [350/500], Loss: 0.6084\n",
            "Train Accuracy: 0.8239, Train F1: 0.8158\n",
            "Val Accuracy: 0.8236, Val F1: 0.8180\n",
            "Epoch [360/500], Loss: 0.6079\n",
            "Train Accuracy: 0.8246, Train F1: 0.8166\n",
            "Val Accuracy: 0.8221, Val F1: 0.8165\n",
            "Epoch [370/500], Loss: 0.6073\n",
            "Train Accuracy: 0.8245, Train F1: 0.8164\n",
            "Val Accuracy: 0.8229, Val F1: 0.8173\n",
            "Epoch [380/500], Loss: 0.6068\n",
            "Train Accuracy: 0.8241, Train F1: 0.8161\n",
            "Val Accuracy: 0.8221, Val F1: 0.8165\n",
            "Epoch [390/500], Loss: 0.6063\n",
            "Train Accuracy: 0.8246, Train F1: 0.8167\n",
            "Val Accuracy: 0.8243, Val F1: 0.8187\n",
            "Epoch [400/500], Loss: 0.6059\n",
            "Train Accuracy: 0.8248, Train F1: 0.8168\n",
            "Val Accuracy: 0.8250, Val F1: 0.8194\n",
            "Epoch [410/500], Loss: 0.6053\n",
            "Train Accuracy: 0.8248, Train F1: 0.8168\n",
            "Val Accuracy: 0.8229, Val F1: 0.8174\n",
            "Epoch [420/500], Loss: 0.6050\n",
            "Train Accuracy: 0.8239, Train F1: 0.8160\n",
            "Val Accuracy: 0.8221, Val F1: 0.8165\n",
            "Epoch [430/500], Loss: 0.6045\n",
            "Train Accuracy: 0.8239, Train F1: 0.8159\n",
            "Val Accuracy: 0.8221, Val F1: 0.8165\n",
            "Epoch [440/500], Loss: 0.6041\n",
            "Train Accuracy: 0.8254, Train F1: 0.8175\n",
            "Val Accuracy: 0.8229, Val F1: 0.8172\n",
            "Epoch [450/500], Loss: 0.6039\n",
            "Train Accuracy: 0.8261, Train F1: 0.8184\n",
            "Val Accuracy: 0.8221, Val F1: 0.8164\n",
            "Epoch [460/500], Loss: 0.6035\n",
            "Train Accuracy: 0.8248, Train F1: 0.8170\n",
            "Val Accuracy: 0.8221, Val F1: 0.8165\n",
            "Epoch [470/500], Loss: 0.6033\n",
            "Train Accuracy: 0.8252, Train F1: 0.8175\n",
            "Val Accuracy: 0.8243, Val F1: 0.8187\n",
            "Epoch [480/500], Loss: 0.6029\n",
            "Train Accuracy: 0.8250, Train F1: 0.8173\n",
            "Val Accuracy: 0.8221, Val F1: 0.8165\n",
            "Epoch [490/500], Loss: 0.6027\n",
            "Train Accuracy: 0.8248, Train F1: 0.8171\n",
            "Val Accuracy: 0.8250, Val F1: 0.8194\n",
            "Epoch [500/500], Loss: 0.6022\n",
            "Train Accuracy: 0.8246, Train F1: 0.8169\n",
            "Val Accuracy: 0.8236, Val F1: 0.8180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Best Model Weights\n"
      ],
      "metadata": {
        "id": "-6gdynbg1hqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model weights based on validation F1 score\n",
        "if best_model_weights is not None:\n",
        "    model.load_state_dict(best_model_weights)"
      ],
      "metadata": {
        "id": "-EIL7eky1cNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Number of Parameters (NOP) Using Thop"
      ],
      "metadata": {
        "id": "DMYuDf-p1rkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import profile\n",
        "\n",
        "# Function to measure NOP using thop\n",
        "def measure_nop(model, inputs):\n",
        "    flops, params = profile(model, inputs=(inputs,))\n",
        "    return flops, params\n",
        "\n",
        "# Test a single sample for NOP calculation\n",
        "sample_input = X_train_tensor[0].unsqueeze(0)\n",
        "flops, params = measure_nop(model, sample_input)\n",
        "NOP = params\n",
        "\n",
        "print(f\"Total trainable parameters after PCA: {NOP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzR4P30Z1orI",
        "outputId": "080c5361-acbc-4ac2-ad99-483a7361a70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "Total trainable parameters after PCA: 11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess Test Data"
      ],
      "metadata": {
        "id": "5dr9OxqH25mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/HerWill/test.csv')\n",
        "\n",
        "# Preprocess the test data\n",
        "test_df['cleaned_passage'] = test_df['passage'].apply(clean_text)\n",
        "for keyword in keywords:\n",
        "    test_df[keyword] = test_df['cleaned_passage'].apply(lambda x: x.count(keyword))\n",
        "for phrase in phrases:\n",
        "    test_df[phrase] = test_df['cleaned_passage'].apply(lambda x: 1 if phrase in x else 0)\n",
        "test_df['keyword_proximity'] = test_df['cleaned_passage'].apply(keyword_proximity)\n",
        "test_df['polarity'] = test_df['cleaned_passage'].apply(text_polarity)"
      ],
      "metadata": {
        "id": "m68OOa2-12PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Test Data Using Trained Vectorizer and Scaler"
      ],
      "metadata": {
        "id": "RmUTSVNS3GOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved vectorizer and scaler\n",
        "vectorizer = joblib.load('/content/drive/MyDrive/HerWill/tfidf_vectorizer.pkl')\n",
        "scaler = joblib.load('/content/drive/MyDrive/HerWill/scaler.pkl')\n",
        "\n",
        "# Transform test data\n",
        "X_tfidf_test = vectorizer.transform(test_df['cleaned_passage'])\n",
        "tfidf_test_df = pd.DataFrame(X_tfidf_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "X_test_combined = pd.concat([tfidf_test_df, test_df[additional_features].reset_index(drop=True)], axis=1)\n",
        "X_scaled_test = scaler.transform(X_test_combined)"
      ],
      "metadata": {
        "id": "wH8dmxUJ2-AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply PCA to Test Data"
      ],
      "metadata": {
        "id": "AnEl2n3D3S0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved PCA model\n",
        "pca = joblib.load('/content/drive/MyDrive/HerWill/pca_model.pkl')\n",
        "X_pca_test = pca.transform(X_scaled_test)\n",
        "X_pca_test_df = pd.DataFrame(X_pca_test, columns=[f'pc_{i}' for i in range(1, 3)])"
      ],
      "metadata": {
        "id": "7yDku2mw3Osb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Test Data to PyTorch Tensor"
      ],
      "metadata": {
        "id": "l_WZujid3uwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test data to tensor\n",
        "X_test_tensor = torch.tensor(X_pca_test_df.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "eLOUB1BY3vU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions on Test Data"
      ],
      "metadata": {
        "id": "LinHsfCq312x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, y_test_pred = torch.max(test_outputs, 1)"
      ],
      "metadata": {
        "id": "v76-kbkJ32WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Output DataFrame with Predictions and NOP"
      ],
      "metadata": {
        "id": "QHDFtk-737bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output DataFrame with predictions and NOP\n",
        "output_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'y_pred': y_test_pred.numpy(),\n",
        "    'parameters': NOP\n",
        "})\n",
        "\n",
        "# Save the predictions\n",
        "output_df.to_csv('/content/drive/MyDrive/HerWill/test_predictions.csv', index=False)\n",
        "print(\"Predictions saved to 'test_predictions.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly1kg8pp37_6",
        "outputId": "e342d7cf-38a9-4987-9455-957ea68783bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'test_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Calculate F1NOP Score"
      ],
      "metadata": {
        "id": "vXmQST7w4BCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1NOP score\n",
        "def calculate_f1nop(f1, nop):\n",
        "    epsilon = 5 * 10**-16\n",
        "    return (0.4 * f1) + (0.6 / (torch.log10(torch.tensor(max(1, nop))) + epsilon))\n",
        "\n",
        "f1nop_score = calculate_f1nop(torch.tensor(best_f1_score), NOP)\n",
        "print(f\"\\nFinal F1NOP Score: {f1nop_score.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sng-yq4T3-ky",
        "outputId": "c471e383-3d2f-45bc-a581-f09b6d850852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final F1NOP Score: 0.9042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(best_model_weights, '/content/drive/MyDrive/HerWill/best_model.pth')\n",
        "print(\"Best model saved as 'best_model.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8RRXGNz6jNc",
        "outputId": "f40d6586-1109-4736-a672-97a10513f569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved as 'best_model.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Text Cleaning: Preprocessing text by converting to lowercase and removing non-alphanumeric characters standardizes inputs, ensuring consistency in feature extraction and reducing noise in model training.\n",
        "\n",
        "> Feature Engineering with Keywords and Phrases: Creating binary features based on specific keywords and phrases related to each class provides additional signals relevant to the classification task, improving model interpretability and potentially enhancing prediction accuracy.\n",
        "\n",
        "> Keyword Proximity Feature: Including proximity-based keyword features captures contextual relationships, which may provide meaningful distinctions among classes by considering adjacent word relationships.\n",
        "\n",
        "> Polarity Feature with Sentiment Analysis: Adding sentiment polarity captures the texts emotional tone, which could aid in identifying nuanced biases or sentiment-driven class distinctions.\n",
        "\n",
        "> TF-IDF Vectorization: Using TF-IDF captures term importance while preserving word frequencies, providing dense numerical representations for words, which benefits the model's ability to capture and distinguish textual patterns.\n",
        "\n",
        "> PCA for Dimensionality Reduction: Reducing dimensionality with PCA condenses relevant information into fewer components, mitigating overfitting and reducing computational load while retaining essential information.\n",
        "\n",
        "> Minimal Neural Network Architecture: Using a compact neural network with few parameters helps prevent overfitting and reduces model complexity, aligning with the aim to create a lightweight, interpretable model.\n"
      ],
      "metadata": {
        "id": "xfiFquoi5Llh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4S4lqdy5Gzz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}